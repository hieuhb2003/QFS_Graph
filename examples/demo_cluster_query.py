#!/usr/bin/env python3
"""
Demo script ƒë·ªÉ test t√≠nh nƒÉng query cluster summaries v·ªõi 2 mode:
- Retrieval mode: Ch·ªâ l·∫•y ra summaries ph√π h·ª£p nh·∫•t t·ª´ vector DB
- Generation mode: L·∫•y summaries t·ª´ vector DB r·ªìi gen c√¢u tr·∫£ l·ªùi b·∫±ng LLM
"""

import asyncio
import os
import sys
from pathlib import Path

# Th√™m src v√†o path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from graphrag.utils.logger_config import setup_logger
from graphrag.core.graphrag_system import GraphRAGSystem
from graphrag.clients.embedding_client import create_embedding_client
from graphrag.clients.llm_client import create_llm_client


async def main():
    """Demo ch√≠nh"""
    print("üöÄ GraphRAG Cluster Summary Query Demo")
    print("=" * 50)
    
    # Setup logger
    logger = setup_logger(
        name="ClusterQueryDemo",
        log_level="INFO",
        log_dir="./logs"
    )
    
    # T·∫°o embedding client
    print("üì° Kh·ªüi t·∫°o embedding client...")
    embedding_client = create_embedding_client(
        client_type="sentence_transformers",
        model_name="all-MiniLM-L6-v2",
        device="cpu"  # S·ª≠ d·ª•ng CPU cho demo
    )
    
    # T·∫°o LLM client (optional - ch·ªâ c·∫ßn cho generation mode)
    llm_client = None
    use_llm = input("ü§ñ B·∫°n c√≥ mu·ªën s·ª≠ d·ª•ng LLM cho generation mode kh√¥ng? (y/n): ").lower().strip()
    
    if use_llm == 'y':
        llm_type = input("Ch·ªçn LLM type (openai/vllm): ").lower().strip()
        
        if llm_type == "openai":
            api_key = input("Nh·∫≠p OpenAI API key: ").strip()
            if api_key:
                llm_client = create_llm_client(
                    client_type="openai",
                    model_name="gpt-3.5-turbo",
                    api_key=api_key
                )
        elif llm_type == "vllm":
            url = input("Nh·∫≠p vLLM URL (m·∫∑c ƒë·ªãnh: http://localhost:8000/v1): ").strip()
            if not url:
                url = "http://localhost:8000/v1"
            llm_client = create_llm_client(
                client_type="vllm",
                model_name="llama2-7b-chat",
                url=url,
                api_key="dummy"
            )
    
    # C·∫•u h√¨nh h·ªá th·ªëng
    global_config = {
        "save_interval": 50,
        "clustering": {
            "outlier_threshold": 5,
            "max_tokens": 4096,
            "batch_size": 8
        },
        "summary": {
            "max_workers": 3,
            "context_length": 2048,
            "query_generation_prompt_template": """
You are an expert assistant. Based on the following cluster summaries, please provide a comprehensive answer to the user's question.

User Question: {query}

Relevant Cluster Summaries:
{summaries}

Requirements:
1. Answer the question based on the information in the cluster summaries
2. Provide specific details and examples from the summaries
3. If the information is not available in the summaries, clearly state that
4. Keep the answer well-structured and informative
5. Cite which clusters the information comes from when relevant
6. Use Vietnamese language for the answer

Answer:
"""
        }
    }
    
    # Kh·ªüi t·∫°o h·ªá th·ªëng
    print("üîß Kh·ªüi t·∫°o GraphRAG system...")
    working_dir = "./demo_cluster_query_data"
    system = GraphRAGSystem(
        working_dir=working_dir,
        embedding_client=embedding_client,
        global_config=global_config,
        llm_client=llm_client
    )
    
    # Sample documents v·ªÅ technology
    sample_documents = [
        "Apple Inc. is a technology company that designs and manufactures consumer electronics, computer software, and online services. Founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in 1976, Apple is known for its innovative products like the iPhone, iPad, and Mac computers.",
        
        "Microsoft Corporation is a multinational technology company that develops, manufactures, licenses, supports, and sells computer software, consumer electronics, and related services. Founded by Bill Gates and Paul Allen in 1975, Microsoft is best known for its Windows operating system and Office productivity suite.",
        
        "Google LLC is a technology company that specializes in internet-related services and products, including online advertising technologies, search engine, cloud computing, software, and hardware. Founded by Larry Page and Sergey Brin in 1998, Google is known for its search engine and Android operating system.",
        
        "Tesla, Inc. is an electric vehicle and clean energy company that designs, develops, manufactures, sells, and leases electric vehicles, energy generation and storage systems, and related services. Founded by Elon Musk in 2003, Tesla is a leader in electric vehicle technology.",
        
        "Amazon.com, Inc. is an American multinational technology company that focuses on e-commerce, cloud computing, digital streaming, and artificial intelligence. Founded by Jeff Bezos in 1994, Amazon is known for its online marketplace and AWS cloud services.",
        
        "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed. It uses algorithms to identify patterns in data and make predictions or decisions.",
        
        "Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers to model and understand complex patterns in data. It has been particularly successful in image recognition, natural language processing, and speech recognition.",
        
        "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves developing algorithms and models to understand, interpret, and generate human language.",
        
        "Computer Vision is a field of artificial intelligence that trains computers to interpret and understand visual information from the world. It involves developing algorithms to process, analyze, and understand images and videos.",
        
        "Artificial Intelligence (AI) is the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses various technologies including machine learning, deep learning, natural language processing, and computer vision."
    ]
    
    try:
        # Insert documents
        print(f"üìÑ ƒêang insert {len(sample_documents)} documents...")
        if llm_client:
            results = await system.insert_documents_batch_with_llm(sample_documents, max_concurrent_docs=3)
        else:
            results = await system.insert_documents_batch(sample_documents, chunk_size=1000, max_concurrent_docs=3)
        
        success_count = sum(results)
        print(f"‚úÖ ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {success_count}/{len(sample_documents)} documents")
        
        # Th·ª±c hi·ªán clustering
        print("üîç ƒêang th·ª±c hi·ªán clustering...")
        clustering_result = await system.cluster_documents(outlier_threshold=5)
        print(f"‚úÖ ƒê√£ t·∫°o {clustering_result.get('n_clusters', 0)} clusters")
        
        # T·∫°o cluster summaries (ch·ªâ khi c√≥ LLM)
        if llm_client:
            print("üìù ƒêang t·∫°o cluster summaries...")
            summaries = await system.generate_cluster_summaries(max_workers=3)
            print(f"‚úÖ ƒê√£ t·∫°o summaries cho {len(summaries)} clusters")
        else:
            print("‚ö†Ô∏è B·ªè qua t·∫°o summaries v√¨ kh√¥ng c√≥ LLM client")
        
        # Demo query v·ªõi retrieval mode
        print("\n" + "="*50)
        print("üîç DEMO RETRIEVAL MODE")
        print("="*50)
        
        retrieval_queries = [
            "technology companies",
            "artificial intelligence",
            "machine learning",
            "Apple and Microsoft"
        ]
        
        for query in retrieval_queries:
            print(f"\n‚ùì Query: {query}")
            result = await system.query_cluster_summaries(
                query=query, 
                mode="retrieval", 
                top_k=3
            )
            
            if "error" in result:
                print(f"‚ùå L·ªói: {result['error']}")
            else:
                print(f"‚úÖ T√¨m th·∫•y {result['total_found']} clusters:")
                for i, cluster_result in enumerate(result['results'], 1):
                    print(f"  {i}. Cluster {cluster_result['cluster_id']} (Score: {cluster_result['score']:.3f})")
                    print(f"     Summary: {cluster_result['summary'][:100]}...")
        
        # Demo query v·ªõi generation mode (ch·ªâ khi c√≥ LLM)
        if llm_client:
            print("\n" + "="*50)
            print("ü§ñ DEMO GENERATION MODE")
            print("="*50)
            
            generation_queries = [
                "What are the main technology companies mentioned?",
                "Explain the relationship between AI and machine learning",
                "What are the key products of Apple and Microsoft?",
                "How does deep learning relate to computer vision?"
            ]
            
            for query in generation_queries:
                print(f"\n‚ùì Query: {query}")
                result = await system.query_cluster_summaries(
                    query=query, 
                    mode="generation", 
                    top_k=3
                )
                
                if "error" in result:
                    print(f"‚ùå L·ªói: {result['error']}")
                else:
                    print(f"‚úÖ Answer: {result['answer']}")
                    print(f"üìä S·ª≠ d·ª•ng {result['total_found']} clusters:")
                    for cluster_result in result['used_summaries']:
                        print(f"  - Cluster {cluster_result['cluster_id']} (Score: {cluster_result['score']:.3f})")
        else:
            print("\n‚ö†Ô∏è B·ªè qua generation mode v√¨ kh√¥ng c√≥ LLM client")
        
        # Hi·ªÉn th·ªã th·ªëng k√™ h·ªá th·ªëng
        print("\n" + "="*50)
        print("üìä SYSTEM STATISTICS")
        print("="*50)
        
        stats = await system.get_system_stats()
        print(f"üìÑ Documents: {stats.get('document_status', {}).get('success', 0)} successful")
        print(f"üîó Graph: {stats.get('graph', {}).get('nodes', 0)} nodes, {stats.get('graph', {}).get('edges', 0)} edges")
        print(f"üìä Vector DBs: {stats.get('vector_dbs', {}).get('entities', 0)} entities, {stats.get('vector_dbs', {}).get('relations', 0)} relations")
        
        # Hi·ªÉn th·ªã cluster info
        cluster_info = await system.get_cluster_info()
        print(f"üîç Clusters: {cluster_info.get('total_clusters', 0)} total, {cluster_info.get('outlier_documents', 0)} outliers")
        
    except Exception as e:
        logger.error(f"L·ªói trong demo: {e}")
        print(f"‚ùå L·ªói: {e}")
    
    finally:
        # Cleanup
        print("\nüßπ ƒêang cleanup...")
        await system.cleanup()
        print("‚úÖ Demo ho√†n th√†nh!")


if __name__ == "__main__":
    asyncio.run(main()) 