"""
Demo Quick Test - GraphRAG System
Demo nhanh Ä‘á»ƒ test táº¥t cáº£ cÃ¡c chá»©c nÄƒng cÆ¡ báº£n
"""

import asyncio
import os
from src.graphrag.core.graphrag_system import GraphRAGSystem
from src.graphrag.clients.llm_client import create_llm_client
from src.graphrag.clients.embedding_client import create_embedding_client
from src.graphrag.utils.logger_config import setup_logger


async def quick_test():
    """Test nhanh táº¥t cáº£ cÃ¡c chá»©c nÄƒng"""
    
    logger = setup_logger(name="Quick-Test", log_level="INFO")
    logger.info("ğŸš€ Báº¯t Ä‘áº§u Quick Test...")
    
    # Khá»Ÿi táº¡o clients
    embedding_client = create_embedding_client(
        client_type="sentence_transformers",
        model_name="all-MiniLM-L6-v2",
        device="cpu"
    )
    
    # LLM client (optional)
    llm_client = None
    if os.getenv("OPENAI_API_KEY"):
        llm_client = create_llm_client(
            client_type="openai",
            model_name="gpt-3.5-turbo",
            api_key=os.getenv("OPENAI_API_KEY")
        )
        logger.info("âœ… CÃ³ LLM client")
    else:
        logger.info("âš ï¸ KhÃ´ng cÃ³ LLM client")
    
    # Khá»Ÿi táº¡o system
    system = GraphRAGSystem(
        working_dir="quick_test_data",
        embedding_client=embedding_client,
        global_config={"save_interval": 10},
        llm_client=llm_client
    )
    
    try:
        # Test documents
        documents = [
            "Apple is a technology company founded by Steve Jobs.",
            "Microsoft develops software and operating systems.",
            "Google specializes in search and internet services.",
            "Machine learning is a subset of artificial intelligence.",
            "Deep learning uses neural networks with multiple layers.",
            "Natural language processing deals with human language.",
            "Computer vision processes visual information.",
            "Tesla makes electric vehicles and clean energy products.",
            "Amazon is an e-commerce and cloud computing company.",
            "Cooking involves preparing food with heat.",
            "Travel means moving from one place to another."
        ]
        
        logger.info(f"ğŸ“ Processing {len(documents)} documents...")
        
        # Insert documents
        if llm_client:
            results = await system.insert_documents_batch_with_llm(documents, max_concurrent_docs=2)
        else:
            results = await system.insert_documents_batch(documents, chunk_size=300, max_concurrent_docs=2)
        
        successful = sum(results)
        logger.info(f"âœ… Inserted {successful}/{len(documents)} documents")
        
        # Get stats
        stats = await system.get_system_stats()
        logger.info(f"ğŸ“Š Stats: {stats}")
        
        # Query entities
        entities = await system.query_entities("technology", top_k=3)
        logger.info(f"ğŸ” Found {len(entities)} entities for 'technology'")
        
        # Clustering
        logger.info("ğŸ¯ Running clustering...")
        clustering_result = await system.cluster_documents(outlier_threshold=3)
        logger.info(f"âœ… Clustering: {clustering_result}")
        
        # Get cluster info
        cluster_info = await system.get_cluster_info()
        logger.info(f"ğŸ“‹ Clusters: {cluster_info}")
        
        # Generate summaries (if LLM available)
        if llm_client:
            summaries = await system.generate_cluster_summaries(max_workers=2)
            if "error" not in summaries:
                logger.info(f"ğŸ“ Generated {len(summaries)} summaries")
            else:
                logger.error(f"âŒ Summary error: {summaries['error']}")
        
        # Query summaries
        if llm_client:
            summary_results = await system.query_cluster_summaries("technology", top_k=2)
            logger.info(f"ğŸ” Found {len(summary_results)} summary matches")
        
        # Get documents by cluster
        for cluster_id in range(clustering_result.get('n_clusters', 0)):
            docs = await system.get_documents_by_cluster(cluster_id)
            logger.info(f"ğŸ“¦ Cluster {cluster_id}: {len(docs)} documents")
        
        # Cleanup
        await system.cleanup()
        logger.info("âœ… Quick test completed successfully!")
        
    except Exception as e:
        logger.error(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        await system.cleanup()


if __name__ == "__main__":
    asyncio.run(quick_test()) 